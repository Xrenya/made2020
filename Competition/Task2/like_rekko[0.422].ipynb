{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T11:16:13.537727Z",
     "start_time": "2020-08-04T11:16:12.034849Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T12:02:31.663568Z",
     "start_time": "2020-08-04T12:02:31.626865Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "df_item = pd.read_csv('input/item-features.csv')\n",
    "df_user = pd.read_csv('input/user-features.csv')\n",
    "subm = pd.read_csv('input/sample-submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T12:02:31.817573Z",
     "start_time": "2020-08-04T12:02:31.810114Z"
    }
   },
   "outputs": [],
   "source": [
    "df_item = df_item.drop(columns=['19','27','30','9'])\n",
    "df_item = df_item.sort_values('item_id').reset_index(drop=True)\n",
    "\n",
    "df_user = df_user.iloc[:, :3]\n",
    "df_user = df_user.sort_values('user_id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T12:02:31.994244Z",
     "start_time": "2020-08-04T12:02:31.986826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>like</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>1490936622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>378</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>1490936628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>1490936650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>455</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1490936704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>350</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>1490936735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  like   timestamp\n",
       "0      140      342     0  1490936622\n",
       "1      378      172     1  1490936628\n",
       "2      150      182     0  1490936650\n",
       "3      455       17     0  1490936704\n",
       "4      350      409     0  1490936735"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T12:02:32.169237Z",
     "start_time": "2020-08-04T12:02:32.158844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((497, 2), (444, 28), (497, 444))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "df_user_np = df_user.iloc[:, 1:]\n",
    "df_item_np = df_item.iloc[:, 1:]\n",
    "\n",
    "y = train['like'].map({0: -1, 1:1}).to_numpy()\n",
    "X_train = train.drop(columns=['like'])\n",
    "\n",
    "data_csr = csr_matrix((y, (X_train['user_id'] , X_train['item_id'])))\n",
    "df_user_np.shape, df_item_np.shape, data_csr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T12:02:32.329969Z",
     "start_time": "2020-08-04T12:02:32.324535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, -1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csr[0, 0], data_csr[378, 172], data_csr[140, 342]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T12:02:33.062351Z",
     "start_time": "2020-08-04T12:02:33.050448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((497, 497), (444, 444))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# считаем косинусное расстояние для пользователей и фильмов \n",
    "# (построчно и поколоночно соотвественно).\n",
    "user_similarity = pairwise_distances(df_user_np, metric='cosine')\n",
    "item_similarity = pairwise_distances(df_item_np, metric='cosine')\n",
    "user_similarity.shape, item_similarity.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article\n",
    "https://makesomecode.me/2018/09/movie-recommendation-system/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T11:51:16.275440Z",
     "start_time": "2020-08-04T11:51:16.270983Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def rmse(prediction, ground_truth):\n",
    "    # Оставим оценки, предсказанные алгоритмом, только для соотвествующего набора данных\n",
    "    prediction = np.nan_to_num(prediction)[ground_truth.nonzero()].flatten()\n",
    "    # Оставим оценки, которые реально поставил пользователь, только для соотвествующего набора данных\n",
    "    ground_truth = np.nan_to_num(ground_truth)[ground_truth.nonzero()].flatten()\n",
    "    \n",
    "    mse = mean_squared_error(prediction, ground_truth)\n",
    "    return sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T12:04:08.723272Z",
     "start_time": "2020-08-04T12:04:08.717792Z"
    }
   },
   "outputs": [],
   "source": [
    "n_users = 497\n",
    "n_movies = 444\n",
    "\n",
    "train_data_matrix = data_csr.toarray()\n",
    "test_data_matrix = data_csr.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T12:04:27.274502Z",
     "start_time": "2020-08-04T12:04:27.018261Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SakaevRF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE:  1.0067670573752832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SakaevRF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\SakaevRF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-based CF RMSE:  1.4781127029402863\n"
     ]
    }
   ],
   "source": [
    "def k_fract_mean_predict(top):\n",
    "    top_similar = np.zeros((n_users, top))\n",
    "    \n",
    "    for i in range(n_users):\n",
    "        user_sim = user_similarity[i]\n",
    "        top_sim_users = user_sim.argsort()[1:top + 1]\n",
    "\n",
    "        for j in range(top):\n",
    "            top_similar[i, j] = top_sim_users[j]\n",
    "            \n",
    "    abs_sim = np.abs(user_similarity)\n",
    "    pred = np.zeros((n_users, n_movies))\n",
    "    \n",
    "    for i in range(n_users):\n",
    "        indexes = top_similar[i].astype(np.int)\n",
    "        numerator = user_similarity[i][indexes]\n",
    "        \n",
    "        mean_rating = np.array([x for x in train_data_matrix[i] if x > 0]).mean()\n",
    "        diff_ratings = train_data_matrix[indexes] - train_data_matrix[indexes].mean()\n",
    "        numerator = numerator.dot(diff_ratings)\n",
    "        denominator = abs_sim[i][top_similar[i].astype(np.int)].sum()\n",
    "        \n",
    "        pred[i] = mean_rating + numerator / denominator\n",
    "        \n",
    "    return pred\n",
    "\n",
    "def k_fract_mean_predict_item(top):\n",
    "    top_similar = np.zeros((n_movies, top))\n",
    "    \n",
    "    for i in range(n_movies):\n",
    "        movie_sim = item_similarity[i]\n",
    "        top_sim_movies = movie_sim.argsort()[1:top + 1]\n",
    "        \n",
    "        for j in range(top):\n",
    "            top_similar[i, j] = top_sim_movies[j]\n",
    "    \n",
    "    abs_sim = np.abs(item_similarity)\n",
    "    pred = np.zeros((n_movies, n_users))\n",
    "    \n",
    "    for i in range(n_movies):\n",
    "        indexes = top_similar[i].astype(np.int)\n",
    "        numerator = item_similarity[i][indexes]\n",
    "        \n",
    "        diff_ratings = train_data_matrix.T[indexes] - train_data_matrix.T[indexes].mean()\n",
    "        numerator = numerator.dot(diff_ratings)\n",
    "        denominator = abs_sim[i][top_similar[i].astype(np.int)].sum()\n",
    "        denominator = denominator if denominator != 0 else 1\n",
    "        \n",
    "        mean_rating = np.array([x for x in train_data_matrix.T[i] if x > 0]).mean()\n",
    "        mean_rating = 0 if np.isnan(mean_rating) else mean_rating\n",
    "        pred[i] = mean_rating + numerator / denominator\n",
    "                \n",
    "    return pred.T\n",
    "\n",
    "k_predict = k_fract_mean_predict(20)\n",
    "print('User-based CF RMSE: ', rmse(k_predict, test_data_matrix))\n",
    "\n",
    "k_predict_item = k_fract_mean_predict_item(20)\n",
    "print('Item-based CF RMSE: ', rmse(k_predict_item, test_data_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T16:49:55.351333Z",
     "start_time": "2020-08-04T16:49:55.345877Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise import NormalPredictor, SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "from surprise.reader import Reader\n",
    "from surprise.dataset import Dataset\n",
    "from surprise import SVD, SVDpp, SlopeOne, NMF, NormalPredictor\n",
    "from surprise import KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore\n",
    "from surprise import BaselineOnly, CoClustering\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T16:43:40.472386Z",
     "start_time": "2020-08-04T16:43:40.445134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>like</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>1490936622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>378</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>1490936628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>1490936650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>455</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1490936704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>350</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>1490936735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  like   timestamp\n",
       "0      140      342     0  1490936622\n",
       "1      378      172     1  1490936628\n",
       "2      150      182     0  1490936650\n",
       "3      455       17     0  1490936704\n",
       "4      350      409     0  1490936735"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T12:17:49.407787Z",
     "start_time": "2020-08-04T12:17:47.323073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.28480864, 0.28737401, 0.29640801, 0.28969182, 0.29218496]),\n",
       " 'test_mae': array([0.17720405, 0.17962929, 0.18028459, 0.18070854, 0.1839145 ]),\n",
       " 'fit_time': (0.39881157875061035,\n",
       "  0.3943197727203369,\n",
       "  0.39627623558044434,\n",
       "  0.39580821990966797,\n",
       "  0.39583539962768555),\n",
       " 'test_time': (0.008928060531616211,\n",
       "  0.008928298950195312,\n",
       "  0.009452104568481445,\n",
       "  0.009424448013305664,\n",
       "  0.008930683135986328)}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(train[['user_id', 'item_id', 'like']], reader)\n",
    "\n",
    "# We can now use this dataset as we please, e.g. calling cross_validate\n",
    "cross_validate(SVD(), data, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), \n",
    "#                   KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]\n",
    "\n",
    "# <class 'surprise.prediction_algorithms.matrix_factorization.SVD'> 0.1825750931054188\n",
    "# <class 'surprise.prediction_algorithms.matrix_factorization.SVDpp'> 0.16760332940541206\n",
    "# <class 'surprise.prediction_algorithms.slope_one.SlopeOne'> 0.15265446170771874\n",
    "# <class 'surprise.prediction_algorithms.random_pred.NormalPredictor'> 0.33987833116682625\n",
    "# <class 'surprise.prediction_algorithms.knns.KNNBaseline'> 0.1297762283632601\n",
    "# <class 'surprise.prediction_algorithms.knns.KNNBasic'> 0.1228509348207455\n",
    "# <class 'surprise.prediction_algorithms.knns.KNNWithMeans'> 0.14724135594053778\n",
    "# <class 'surprise.prediction_algorithms.knns.KNNWithZScore'> 0.14440677662246001\n",
    "# <class 'surprise.prediction_algorithms.baseline_only.BaselineOnly'> 0.1839018552188873\n",
    "# <class 'surprise.prediction_algorithms.co_clustering.CoClustering'> 0.15628048493380628"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T17:03:17.948204Z",
     "start_time": "2020-08-04T17:03:02.231796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'surprise.prediction_algorithms.matrix_factorization.SVD'> 0.1825750931054188\n",
      "<class 'surprise.prediction_algorithms.matrix_factorization.SVDpp'> 0.16760332940541206\n",
      "<class 'surprise.prediction_algorithms.slope_one.SlopeOne'> 0.15265446170771874\n",
      "<class 'surprise.prediction_algorithms.random_pred.NormalPredictor'> 0.33987833116682625\n",
      "<class 'surprise.prediction_algorithms.knns.KNNBaseline'> 0.1297762283632601\n",
      "<class 'surprise.prediction_algorithms.knns.KNNBasic'> 0.1228509348207455\n",
      "<class 'surprise.prediction_algorithms.knns.KNNWithMeans'> 0.14724135594053778\n",
      "<class 'surprise.prediction_algorithms.knns.KNNWithZScore'> 0.14440677662246001\n",
      "<class 'surprise.prediction_algorithms.baseline_only.BaselineOnly'> 0.1839018552188873\n",
      "<class 'surprise.prediction_algorithms.co_clustering.CoClustering'> 0.15628048493380628\n"
     ]
    }
   ],
   "source": [
    "algos = [SVD(), SVDpp(), SlopeOne(), NormalPredictor(), KNNBaseline(verbose=False), KNNBasic(verbose=False), \n",
    "         KNNWithMeans(verbose=False), KNNWithZScore(verbose=False), \n",
    "         BaselineOnly(verbose=False), CoClustering()]\n",
    "\n",
    "for algorithm in algos:\n",
    "    \n",
    "    result = cross_validate(algorithm, data, cv=5)\n",
    "    print(algorithm.__class__, result['test_mae'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T17:03:47.784821Z",
     "start_time": "2020-08-04T17:03:41.709817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14792045242869906\n"
     ]
    }
   ],
   "source": [
    "# 0.14098334301265458\n",
    "\n",
    "algorithm = SVDpp(n_factors=5, lr_all=0.1, reg_all=0.02)  # , reg_all=0.02\n",
    "\n",
    "result = cross_validate(algorithm, data, cv=5)\n",
    "print(result['test_mae'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T17:04:48.671357Z",
     "start_time": "2020-08-04T17:04:44.613087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11949606732813518\n"
     ]
    }
   ],
   "source": [
    "# 0.11899593180524995\n",
    "\n",
    "algorithm = KNNBasic(k=7, verbose=False)\n",
    "\n",
    "res_sum = list()\n",
    "for i in range(10):\n",
    "    result = cross_validate(algorithm, data, cv=5)\n",
    "    res_sum.append(result['test_mae'].mean())\n",
    "print(np.mean(res_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T17:15:08.024906Z",
     "start_time": "2020-08-04T17:15:02.919971Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "\n",
    "algo = KNNBasic(k=7, verbose=False)\n",
    "algo.fit(data.build_full_trainset())\n",
    "\n",
    "# Than predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "top_n = get_top_n(predictions, n=20)\n",
    "y_pred = pd.DataFrame.from_dict({k: [z[0] for z in v] for k, v in top_n.items()}).T.reset_index()\n",
    "y_pred = y_pred.rename(columns={'index': 'user_id'})\n",
    "\n",
    "# Print the recommended items for each user\n",
    "# for uid, user_ratings in top_n.items():\n",
    "#     print(uid, [iid for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T17:15:11.876506Z",
     "start_time": "2020-08-04T17:15:11.871050Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['user_id', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11',\n",
       "        '12', '13', '14', '15', '16', '17', '18', '19'],\n",
       "       dtype='object'),\n",
       " Index(['user_id', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.columns, y_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T17:16:17.290727Z",
     "start_time": "2020-08-04T17:16:17.286236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((497, 21), (497, 21))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T17:16:28.587368Z",
     "start_time": "2020-08-04T17:16:28.578439Z"
    }
   },
   "outputs": [],
   "source": [
    "subm.iloc[:, 1:] = subm.iloc[:, :1].merge(y_pred, on='user_id').iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T17:17:08.509572Z",
     "start_time": "2020-08-04T17:17:08.500147Z"
    }
   },
   "outputs": [],
   "source": [
    "subm.to_csv('input/subm004.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T17:39:02.932407Z",
     "start_time": "2020-08-04T17:39:02.922458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>like</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1490945876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1490947707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1490988759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1491008981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>1491014450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>1</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>1491032049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>1491051735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4109</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1491064028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1491083480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1491112270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5627</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1491112954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5635</th>\n",
       "      <td>1</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>1491113281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5782</th>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1491118112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>1</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>1491128031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7627</th>\n",
       "      <td>1</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>1491178010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>1</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>1491201390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8445</th>\n",
       "      <td>1</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>1491206499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8654</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>1491214948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  like   timestamp\n",
       "298         1       54     0  1490945876\n",
       "366         1       20     0  1490947707\n",
       "1675        1        0     0  1490988759\n",
       "2328        1       27     0  1491008981\n",
       "2506        1      108     0  1491014450\n",
       "3069        1      213     0  1491032049\n",
       "3721        1      210     0  1491051735\n",
       "4109        1        4     1  1491064028\n",
       "4739        1      132     0  1491083480\n",
       "5607        1        5     1  1491112270\n",
       "5627        1        3     1  1491112954\n",
       "5635        1      218     0  1491113281\n",
       "5782        1       96     0  1491118112\n",
       "6087        1      217     0  1491128031\n",
       "7627        1      214     0  1491178010\n",
       "8308        1      215     0  1491201390\n",
       "8445        1      211     0  1491206499\n",
       "8654        1      125     0  1491214948"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.user_id==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T17:37:47.094379Z",
     "start_time": "2020-08-04T17:37:47.075063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>105</td>\n",
       "      <td>35</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>87</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>103</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>136</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>35</td>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>102</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>191</td>\n",
       "      <td>55</td>\n",
       "      <td>145</td>\n",
       "      <td>37</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>142</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>105</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "      <td>182</td>\n",
       "      <td>26</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>80</td>\n",
       "      <td>101</td>\n",
       "      <td>65</td>\n",
       "      <td>24</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>181</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>102</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>35</td>\n",
       "      <td>182</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>127</td>\n",
       "      <td>72</td>\n",
       "      <td>49</td>\n",
       "      <td>73</td>\n",
       "      <td>37</td>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>492</td>\n",
       "      <td>35</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>72</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>103</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>86</td>\n",
       "      <td>167</td>\n",
       "      <td>98</td>\n",
       "      <td>170</td>\n",
       "      <td>136</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>493</td>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>119</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>98</td>\n",
       "      <td>37</td>\n",
       "      <td>60</td>\n",
       "      <td>171</td>\n",
       "      <td>110</td>\n",
       "      <td>8</td>\n",
       "      <td>142</td>\n",
       "      <td>199</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>494</td>\n",
       "      <td>35</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>75</td>\n",
       "      <td>186</td>\n",
       "      <td>103</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>86</td>\n",
       "      <td>167</td>\n",
       "      <td>98</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>495</td>\n",
       "      <td>168</td>\n",
       "      <td>205</td>\n",
       "      <td>207</td>\n",
       "      <td>177</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>125</td>\n",
       "      <td>43</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>94</td>\n",
       "      <td>14</td>\n",
       "      <td>69</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>174</td>\n",
       "      <td>75</td>\n",
       "      <td>79</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>496</td>\n",
       "      <td>35</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>94</td>\n",
       "      <td>15</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>186</td>\n",
       "      <td>103</td>\n",
       "      <td>147</td>\n",
       "      <td>49</td>\n",
       "      <td>86</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>136</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id    0    1    2    3   4    5    6    7    8  ...   10   11   12  \\\n",
       "393        0   95  105   35   80  65   66   22   39   11  ...   15   87    7   \n",
       "152        1  105   35   65   22  11   15  102   76   72  ...  191   55  145   \n",
       "81         2   30  105   21   23  35   44  182   26   65  ...   24   34   50   \n",
       "114        3  105   21   23   35  80  101   65   24   66  ...  181   14   40   \n",
       "210        4  105   35  182   24  22   11   64   15   45  ...   76  127   72   \n",
       "..       ...  ...  ...  ...  ...  ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "79       492   35   65   58   24  66   22   15   72  202  ...  186  103   19   \n",
       "345      493   35   58   66   22  40   76   72  119   19  ...   86   98   37   \n",
       "260      494   35   65   58   24  66   22   15   76   72  ...  202   75  186   \n",
       "332      495  168  205  207  177   4   80  125   43   65  ...   22   94   14   \n",
       "387      496   35   65   58   24  66   22   94   15   72  ...   75  186  103   \n",
       "\n",
       "      13   14   15   16   17   18   19  \n",
       "393   76  103   19   18   49  136   37  \n",
       "152   37   60  110    1  192  142   85  \n",
       "81    66   22   39   11   40   45    7  \n",
       "114   45  102    7   48   76   75  147  \n",
       "210   49   73   37   31   60  110    8  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  \n",
       "79    49   86  167   98  170  136   37  \n",
       "345   60  171  110    8  142  199   85  \n",
       "260  103   19   49   86  167   98  170  \n",
       "332   69   76   72  174   75   79  147  \n",
       "387  147   49   86  167  170  136   37  \n",
       "\n",
       "[497 rows x 21 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.sort_values('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T05:52:59.369207Z",
     "start_time": "2020-08-04T05:52:59.259398Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T06:34:57.921058Z",
     "start_time": "2020-08-04T06:34:57.902109Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_k(model, X_test, item_params, k=20):\n",
    "    items_data = item_params.iloc[:, 1:].values\n",
    "    n_items = len(item_params)\n",
    "    y_pred = list()\n",
    "    \n",
    "    for user_idx in range(X_test.shape[0]):\n",
    "#         result = pd.DataFrame(columns=['item_id', 'proba'])\n",
    "#         result['item_id'] = range(n_items)\n",
    "        \n",
    "        user_data = np.tile(X_test[[user_idx]], (n_items, 1))\n",
    "        data = np.concatenate([user_data, items_data], axis=1)\n",
    "        \n",
    "        pred = model.predict(data)\n",
    "        y_pred.append(pred)\n",
    "        \n",
    "#         result['proba'] = model.predict(data)\n",
    "#         result = result.sort_values('proba', ascending=False)\n",
    "#         y_pred.append(result['item_id'].values)\n",
    "        \n",
    "    return np.array(y_pred)\n",
    "\n",
    "\n",
    "def train_model(X, X_test, y, params, folds, model_type='lgb', averaging='usual', \n",
    "                verbose_eval=False, plot_feature_importance=False):\n",
    "    oof = np.zeros(len(X))\n",
    "    prediction = np.zeros((len(X_test), len(df_item)))\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "        if verbose_eval:\n",
    "            print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X[train_index], X[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            train_data = lgb.Dataset(X_train, label=y_train, params={'verbose': -1})\n",
    "            valid_data = lgb.Dataset(X_valid, label=y_valid, params={'verbose': -1})\n",
    "            \n",
    "            model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=20000,\n",
    "                    valid_sets = [train_data, valid_data],\n",
    "                    verbose_eval=verbose_eval,\n",
    "                    early_stopping_rounds = 200)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = predict_k(model, X_test, df_item)\n",
    "            \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        scores.append(roc_auc_score(y_valid, y_pred_valid))\n",
    "\n",
    "        if averaging == 'usual':\n",
    "            prediction += y_pred\n",
    "        elif averaging == 'rank':\n",
    "            prediction += pd.Series(y_pred).rank().values  \n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = [f'col{ncol}' for ncol in range(X.shape[-1])]\n",
    "            fold_importance[\"importance\"] = model.feature_importance()\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_fold\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        feature_importance[\"importance\"] /= n_fold\n",
    "        if plot_feature_importance:\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                   by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "        \n",
    "            return oof, prediction, feature_importance\n",
    "        return oof, prediction, scores\n",
    "    \n",
    "    else:\n",
    "        return oof, prediction, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T06:38:02.373745Z",
     "start_time": "2020-08-04T06:38:02.369759Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "# folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "# folds = TimeSeriesSplit(n_splits=n_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T06:40:28.694645Z",
     "start_time": "2020-08-04T06:40:28.690656Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'boost': 'gbdt', \n",
    "          'feature_fraction': 0.5, \n",
    "          'lambda_l2': 0.57, \n",
    "          'learning_rate': 0.01, \n",
    "          'max_depth': 13, \n",
    "          'metric': 'auc', \n",
    "          'min_data_in_leaf': 63, \n",
    "          'num_leaves': 226, \n",
    "          'num_threads': -1, \n",
    "          'objective': 'binary', \n",
    "          'verbosity': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T07:00:11.906913Z",
     "start_time": "2020-08-04T07:00:11.897937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8674, 37), (497, 9))"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train.values\n",
    "y_like = y.values.flatten()\n",
    "X_test_np = X_test.values\n",
    "X.shape, X_test_np.shape\n",
    "\n",
    "# X = X_train.values[:, 1:]\n",
    "# y_like = y.values.flatten()\n",
    "# X_test_np = X_test.values[:, 1:]\n",
    "# X.shape, X_test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T07:00:19.295191Z",
     "start_time": "2020-08-04T07:00:12.088475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.5594, std: 0.0207.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "oof_lgb, prediction_lgb, scores = train_model(X, X_test_np, y_like, params=params, plot_feature_importance=True,\n",
    "                                              folds=folds, model_type='lgb', verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T06:43:52.658229Z",
     "start_time": "2020-08-04T06:43:52.644266Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = np.zeros((prediction_lgb.shape[0], 20), dtype=int)\n",
    "\n",
    "for i in range(prediction_lgb.shape[0]):\n",
    "    pred[i] = np.argsort(prediction_lgb[i])[::-1][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T06:00:59.250021Z",
     "start_time": "2020-08-04T06:00:58.286576Z"
    }
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T06:05:13.512850Z",
     "start_time": "2020-08-04T06:05:13.505868Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_max(hp_params):\n",
    "    oof_lgb, prediction_lgb, scores = train_model(X, X_test_np, y_like, params=hp_params, \n",
    "                                                  folds=folds, model_type='lgb')\n",
    "    return -np.mean(scores)\n",
    "\n",
    "lgb_params = {'boost': 'gbdt',\n",
    "          'feature_fraction': hp.uniform('feature_fraction', 0.05, 1),\n",
    "          'learning_rate': 0.01,\n",
    "          'max_depth': hp.choice('max_depth', [5, 9, 13, 17, 23, -1]),  \n",
    "          'metric': 'auc',\n",
    "          'min_data_in_leaf': hp.uniformint('min_data_in_leaf', 11, 151),\n",
    "          'num_leaves': hp.uniformint('num_leaves', 31, 351),\n",
    "          'num_threads': -1,\n",
    "          'verbosity': -1,\n",
    "          'lambda_l2': hp.uniform('lambda_l2', 0, 3),\n",
    "          'objective': 'binary',\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T06:21:24.867938Z",
     "start_time": "2020-08-04T06:05:14.200854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.5484, std: 0.0200.                                                                                    \n",
      "CV mean score: 0.5467, std: 0.0220.                                                                                    \n",
      "CV mean score: 0.5564, std: 0.0230.                                                                                    \n",
      "CV mean score: 0.5495, std: 0.0140.                                                                                    \n",
      "CV mean score: 0.5495, std: 0.0151.                                                                                    \n",
      "CV mean score: 0.5576, std: 0.0178.                                                                                    \n",
      "CV mean score: 0.5511, std: 0.0202.                                                                                    \n",
      "CV mean score: 0.5544, std: 0.0140.                                                                                    \n",
      "CV mean score: 0.5574, std: 0.0181.                                                                                    \n",
      "CV mean score: 0.5529, std: 0.0246.                                                                                    \n",
      "CV mean score: 0.5442, std: 0.0133.                                                                                    \n",
      "CV mean score: 0.5474, std: 0.0143.                                                                                    \n",
      "CV mean score: 0.5538, std: 0.0165.                                                                                    \n",
      "CV mean score: 0.5530, std: 0.0149.                                                                                    \n",
      "CV mean score: 0.5524, std: 0.0187.                                                                                    \n",
      "CV mean score: 0.5482, std: 0.0129.                                                                                    \n",
      "CV mean score: 0.5516, std: 0.0137.                                                                                    \n",
      "CV mean score: 0.5524, std: 0.0211.                                                                                    \n",
      "CV mean score: 0.5575, std: 0.0123.                                                                                    \n",
      "CV mean score: 0.5537, std: 0.0147.                                                                                    \n",
      "CV mean score: 0.5471, std: 0.0107.                                                                                    \n",
      "CV mean score: 0.5526, std: 0.0101.                                                                                    \n",
      "CV mean score: 0.5529, std: 0.0151.                                                                                    \n",
      "CV mean score: 0.5472, std: 0.0146.                                                                                    \n",
      "CV mean score: 0.5532, std: 0.0149.                                                                                    \n",
      "CV mean score: 0.5493, std: 0.0158.                                                                                    \n",
      "CV mean score: 0.5500, std: 0.0034.                                                                                    \n",
      "CV mean score: 0.5469, std: 0.0156.                                                                                    \n",
      "CV mean score: 0.5563, std: 0.0151.                                                                                    \n",
      "CV mean score: 0.5491, std: 0.0120.                                                                                    \n",
      "CV mean score: 0.5485, std: 0.0196.                                                                                    \n",
      "CV mean score: 0.5543, std: 0.0151.                                                                                    \n",
      "CV mean score: 0.5509, std: 0.0234.                                                                                    \n",
      "CV mean score: 0.5504, std: 0.0153.                                                                                    \n",
      "CV mean score: 0.5478, std: 0.0203.                                                                                    \n",
      "CV mean score: 0.5582, std: 0.0183.                                                                                    \n",
      "CV mean score: 0.5444, std: 0.0171.                                                                                    \n",
      "CV mean score: 0.5494, std: 0.0206.                                                                                    \n",
      "CV mean score: 0.5552, std: 0.0199.                                                                                    \n",
      "CV mean score: 0.5559, std: 0.0126.                                                                                    \n",
      "CV mean score: 0.5572, std: 0.0258.                                                                                    \n",
      "CV mean score: 0.5475, std: 0.0193.                                                                                    \n",
      "CV mean score: 0.5537, std: 0.0156.                                                                                    \n",
      "CV mean score: 0.5538, std: 0.0166.                                                                                    \n",
      "CV mean score: 0.5564, std: 0.0096.                                                                                    \n",
      "CV mean score: 0.5526, std: 0.0216.                                                                                    \n",
      "CV mean score: 0.5510, std: 0.0130.                                                                                    \n",
      "CV mean score: 0.5541, std: 0.0184.                                                                                    \n",
      "CV mean score: 0.5501, std: 0.0160.                                                                                    \n",
      "CV mean score: 0.5552, std: 0.0162.                                                                                    \n",
      "CV mean score: 0.5520, std: 0.0198.                                                                                    \n",
      "CV mean score: 0.5547, std: 0.0123.                                                                                    \n",
      "CV mean score: 0.5515, std: 0.0107.                                                                                    \n",
      "CV mean score: 0.5517, std: 0.0209.                                                                                    \n",
      "CV mean score: 0.5481, std: 0.0190.                                                                                    \n",
      "CV mean score: 0.5560, std: 0.0234.                                                                                    \n",
      "CV mean score: 0.5489, std: 0.0108.                                                                                    \n",
      "CV mean score: 0.5453, std: 0.0176.                                                                                    \n",
      "CV mean score: 0.5511, std: 0.0087.                                                                                    \n",
      "CV mean score: 0.5541, std: 0.0151.                                                                                    \n",
      "CV mean score: 0.5540, std: 0.0156.                                                                                    \n",
      "CV mean score: 0.5446, std: 0.0093.                                                                                    \n",
      "CV mean score: 0.5581, std: 0.0228.                                                                                    \n",
      "CV mean score: 0.5455, std: 0.0163.                                                                                    \n",
      "CV mean score: 0.5497, std: 0.0071.                                                                                    \n",
      "CV mean score: 0.5591, std: 0.0171.                                                                                    \n",
      "CV mean score: 0.5536, std: 0.0154.                                                                                    \n",
      "CV mean score: 0.5563, std: 0.0208.                                                                                    \n",
      "CV mean score: 0.5508, std: 0.0146.                                                                                    \n",
      "CV mean score: 0.5522, std: 0.0058.                                                                                    \n",
      "CV mean score: 0.5594, std: 0.0207.                                                                                    \n",
      "CV mean score: 0.5514, std: 0.0150.                                                                                    \n",
      "CV mean score: 0.5548, std: 0.0156.                                                                                    \n",
      "CV mean score: 0.5564, std: 0.0203.                                                                                    \n",
      "CV mean score: 0.5523, std: 0.0158.                                                                                    \n",
      "CV mean score: 0.5564, std: 0.0167.                                                                                    \n",
      "CV mean score: 0.5509, std: 0.0173.                                                                                    \n",
      "CV mean score: 0.5545, std: 0.0238.                                                                                    \n",
      "CV mean score: 0.5491, std: 0.0186.                                                                                    \n",
      "CV mean score: 0.5521, std: 0.0173.                                                                                    \n",
      "CV mean score: 0.5540, std: 0.0207.                                                                                    \n",
      "CV mean score: 0.5470, std: 0.0093.                                                                                    \n",
      "CV mean score: 0.5522, std: 0.0145.                                                                                    \n",
      "CV mean score: 0.5520, std: 0.0173.                                                                                    \n",
      "CV mean score: 0.5547, std: 0.0172.                                                                                    \n",
      "CV mean score: 0.5579, std: 0.0131.                                                                                    \n",
      "CV mean score: 0.5530, std: 0.0184.                                                                                    \n",
      "CV mean score: 0.5527, std: 0.0158.                                                                                    \n",
      "CV mean score: 0.5479, std: 0.0052.                                                                                    \n",
      "CV mean score: 0.5529, std: 0.0165.                                                                                    \n",
      "CV mean score: 0.5503, std: 0.0168.                                                                                    \n",
      "CV mean score: 0.5516, std: 0.0165.                                                                                    \n",
      "CV mean score: 0.5434, std: 0.0180.                                                                                    \n",
      "CV mean score: 0.5564, std: 0.0165.                                                                                    \n",
      "CV mean score: 0.5535, std: 0.0143.                                                                                    \n",
      "CV mean score: 0.5496, std: 0.0117.                                                                                    \n",
      "CV mean score: 0.5540, std: 0.0184.                                                                                    \n",
      "CV mean score: 0.5540, std: 0.0170.                                                                                    \n",
      "CV mean score: 0.5535, std: 0.0159.                                                                                    \n",
      "CV mean score: 0.5512, std: 0.0154.                                                                                    \n",
      "100%|████████████████████████████████████████████████| 100/100 [16:10<00:00,  7.22s/it, best loss: -0.5594155787840644]\n",
      "{'feature_fraction': 0.4996105709851735, 'lambda_l2': 0.5664981514489538, 'max_depth': 2, 'min_data_in_leaf': 63.0, 'num_leaves': 226.0}\n",
      "{'boost': 'gbdt', 'feature_fraction': 0.4996105709851735, 'lambda_l2': 0.5664981514489538, 'learning_rate': 0.01, 'max_depth': 13, 'metric': 'auc', 'min_data_in_leaf': 63, 'num_leaves': 226, 'num_threads': -1, 'objective': 'binary', 'verbosity': -1}\n"
     ]
    }
   ],
   "source": [
    "# minimize the objective over the space\n",
    "from hyperopt import fmin, tpe, space_eval\n",
    "best = fmin(to_max, lgb_params, algo=tpe.suggest, max_evals=100)\n",
    "\n",
    "print(best)\n",
    "print(space_eval(lgb_params, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "scaler = MinMaxScaler()  # StandardScaler()\n",
    "df_item_np = csr_matrix(scaler.fit_transform(df_item.iloc[:, 1:]))\n",
    "\n",
    "# df_user_np = csr_matrix(df_user.iloc[:, [1]].values)\n",
    "df_user_np = csr_matrix(scaler.fit_transform(df_user.iloc[:, [1]].values))\n",
    "\n",
    "y_np = y.map({0:-1, 1:1}).values\n",
    "\n",
    "data_csr = csr_matrix((y_np, (train['user_id'] , train['item_id'])))\n",
    "\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "item_sim = linear_kernel(df_item_np, df_item_np)\n",
    "item_sim = csr_matrix(item_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T09:09:37.975279Z",
     "start_time": "2020-08-04T09:09:37.968335Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T09:22:16.992191Z",
     "start_time": "2020-08-04T09:22:16.981223Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()  # StandardScaler()\n",
    "df_item_np = csr_matrix(scaler.fit_transform(df_item.iloc[:, 1:]))\n",
    "\n",
    "# df_user_np = csr_matrix(df_user.iloc[:, [1]].values)\n",
    "df_user_np = csr_matrix(scaler.fit_transform(df_user.iloc[:, [1]].values))\n",
    "\n",
    "y_np = y.map({0:-1, 1:1}).values\n",
    "\n",
    "data_csr = csr_matrix((y_np, (train['user_id'] , train['item_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T09:22:17.315818Z",
     "start_time": "2020-08-04T09:22:17.283726Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "item_sim = linear_kernel(df_item_np, df_item_np)\n",
    "item_sim = csr_matrix(item_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T09:19:08.959731Z",
     "start_time": "2020-08-04T09:19:08.954769Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LightFM(no_components=30, loss='warp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T09:19:16.028244Z",
     "start_time": "2020-08-04T09:19:09.645293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08209256\n"
     ]
    }
   ],
   "source": [
    "# 0.08209256\n",
    "\n",
    "model = LightFM(no_components=50, loss='warp', random_state=11)\n",
    "model.fit(data_csr,\n",
    "          user_features=df_user_np,\n",
    "          item_features=df_item_np,\n",
    "          epochs=50)\n",
    "\n",
    "train_precision = precision_at_k(model, data_csr, user_features=df_user_np, item_features=df_item_np, k=20).mean()\n",
    "\n",
    "print(train_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T05:11:05.279143Z",
     "start_time": "2020-08-04T05:11:03.596619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07605634\n"
     ]
    }
   ],
   "source": [
    "# 0.02\n",
    "\n",
    "model = LightFM(no_components=30, loss='warp', random_state=11)\n",
    "model.fit(data_csr,\n",
    "          item_features=df_item_np,\n",
    "          epochs=20)\n",
    "\n",
    "train_precision = precision_at_k(model, data_csr, item_features=df_item_np, k=20).mean()\n",
    "\n",
    "print(train_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T05:08:10.923545Z",
     "start_time": "2020-08-04T05:08:10.495691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10150906\n"
     ]
    }
   ],
   "source": [
    "model = LightFM(no_components=60, loss='warp', random_state=11)\n",
    "model.fit(data_csr,\n",
    "          user_features=df_user_np,\n",
    "          epochs=20)\n",
    "\n",
    "train_precision = precision_at_k(model, data_csr, user_features=df_user_np, k=20).mean()\n",
    "\n",
    "print(train_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T05:08:11.707448Z",
     "start_time": "2020-08-04T05:08:10.924543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22072434\n"
     ]
    }
   ],
   "source": [
    "model = LightFM(no_components=60, loss='warp', random_state=11, max_sampled=250)\n",
    "model.fit(data_csr,\n",
    "          epochs=20)\n",
    "\n",
    "train_precision = precision_at_k(model, data_csr, k=20).mean()\n",
    "\n",
    "print(train_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPEROPT FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_alpha, user_alpha, max_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T09:19:21.597846Z",
     "start_time": "2020-08-04T09:19:21.592818Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_max_fm_all(hp_params):\n",
    "    model = LightFM(**hp_params)\n",
    "    model.fit(data_csr,\n",
    "              user_features=df_user_np,\n",
    "              item_features=df_item_np,\n",
    "              epochs=50)\n",
    "    \n",
    "    train_precision = precision_at_k(model, data_csr, user_features=df_user_np, \n",
    "                                     item_features=df_item_np, k=20).mean()\n",
    "\n",
    "    return -train_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T09:27:32.844525Z",
     "start_time": "2020-08-04T09:27:32.836547Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_max_fm(hp_params):\n",
    "    model = LightFM(**hp_params)\n",
    "    model.fit(data_csr, epochs=20)\n",
    "    train_precision = precision_at_k(model, data_csr, k=20).mean()\n",
    "    return -train_precision\n",
    "\n",
    "def to_max_fm_all(hp_params):\n",
    "    try:\n",
    "        model = LightFM(**hp_params)\n",
    "        model.fit(data_csr,\n",
    "                  user_features=df_user_np,\n",
    "                  item_features=df_item_np,\n",
    "                  epochs=50)\n",
    "\n",
    "        train_precision = precision_at_k(model, data_csr, user_features=df_user_np, \n",
    "                                         item_features=df_item_np, k=20).mean()\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "    return -train_precision\n",
    "\n",
    "hp_params = {'no_components': hp.uniformint('no_components', 10, 150),\n",
    "              'loss': 'warp',\n",
    "              'random_state': 11,\n",
    "              'item_alpha': hp.uniform('item_alpha', 0, 0.5),  \n",
    "              'user_alpha': hp.uniform('user_alpha', 0, 0.5),  \n",
    "              'max_sampled': hp.uniformint('max_sampled', 10, 500),\n",
    "             'learning_rate': 0.01\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T09:44:27.596361Z",
     "start_time": "2020-08-04T09:27:37.717841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11%|█████▍                                           | 11/100 [01:40<11:59,  8.08s/it, best loss: -0.0825955793261528]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SakaevRF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27%|█████████████▏                                   | 27/100 [03:39<11:12,  9.21s/it, best loss: -0.0825955793261528]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SakaevRF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████▏                              | 37/100 [05:18<09:17,  8.85s/it, best loss: -0.0825955793261528]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SakaevRF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████                            | 43/100 [06:38<13:29, 14.21s/it, best loss: -0.0825955793261528]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SakaevRF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 100/100 [16:49<00:00, 15.67s/it, best loss: -0.08360160887241364]\n",
      "{'item_alpha': 0.08047197091783757, 'max_sampled': 249.0, 'no_components': 95.0, 'user_alpha': 0.09924232044168897}\n",
      "{'item_alpha': 0.08047197091783757, 'learning_rate': 0.01, 'loss': 'warp', 'max_sampled': 249, 'no_components': 95, 'random_state': 11, 'user_alpha': 0.09924232044168897}\n"
     ]
    }
   ],
   "source": [
    "# minimize the objective over the space\n",
    "from hyperopt import fmin, tpe, space_eval\n",
    "best = fmin(to_max_fm_all, hp_params, algo=tpe.suggest, max_evals=100)\n",
    "\n",
    "print(best)\n",
    "print(space_eval(hp_params, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T05:25:39.046383Z",
     "start_time": "2020-08-04T05:23:34.965499Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True False False False False False  True False  True\n",
      "  True  True False False False  True  True False False  True False  True\n",
      " False  True  True  True] 0.08269618\n",
      "[False  True False False False False  True False  True  True  True  True\n",
      "  True False False  True False  True  True False False  True  True  True\n",
      " False False False False] 0.07354125\n",
      "[False  True False False  True False False False False  True False  True\n",
      " False  True  True  True False  True  True False  True  True False  True\n",
      " False  True  True False] 0.08028169\n",
      "[False  True False  True False False  True False False  True False  True\n",
      "  True  True False  True  True  True False  True  True False False  True\n",
      " False False False False] 0.07233401\n",
      "[False  True False  True  True False  True  True False  True  True False\n",
      " False  True  True  True False False  True False  True  True False False\n",
      " False False False False] 0.07877264\n",
      "[ True  True False False False False  True False  True  True  True False\n",
      "  True  True  True False False False False  True False False  True False\n",
      " False  True False  True] 0.07595573\n",
      "[False  True  True False  True False  True False False False False False\n",
      " False False  True False  True  True  True  True  True  True  True False\n",
      "  True False  True False] 0.075855136\n",
      "[ True False  True False  True False  True  True  True False  True False\n",
      "  True  True  True False False  True  True False  True False False  True\n",
      " False False False  True] 0.08259558\n",
      "[ True  True False False  True  True False False  True  True  True  True\n",
      "  True False  True False  True  True  True  True False False False False\n",
      "  True  True  True False] 0.0804829\n",
      "[ True False False False False False False False False  True  True False\n",
      " False False False False False  True False False  True False False False\n",
      " False False False False] 0.069315895\n",
      "[False  True False  True  True False False False  True False False False\n",
      "  True  True  True  True  True False False  True False False  True False\n",
      "  True  True False False] 0.07565392\n",
      "[False False  True  True False False  True False  True False False  True\n",
      "  True False False False  True False False False  True  True False False\n",
      " False  True False False] 0.07696177\n",
      "[False  True  True  True False False  True  True False  True False  True\n",
      " False False  True False  True False  True False False False  True  True\n",
      " False  True  True  True] 0.08028169\n",
      "[ True  True  True False False False  True  True False  True False False\n",
      " False False False False  True  True  True False  True  True  True False\n",
      "  True False False False] 0.07253522\n",
      "[False  True  True False False False  True  True  True  True  True False\n",
      "  True False  True  True False False False  True  True  True  True False\n",
      " False False  True False] 0.07957747\n",
      "[ True  True False  True  True  True False  True False  True False  True\n",
      " False False False  True False  True False False False False  True False\n",
      " False False  True  True] 0.08239436\n",
      "[False  True False False False  True False False  True False False False\n",
      "  True False  True  True  True False  True  True  True False  True  True\n",
      " False  True  True  True] 0.07374246\n",
      "[ True False False False  True  True  True False False  True  True  True\n",
      "  True  True False  True False False  True False False False  True  True\n",
      " False False False  True] 0.08189135\n",
      "[ True False  True False False  True  True False  True  True  True False\n",
      " False False  True False  True False  True False False  True  True  True\n",
      " False False False False] 0.07565392\n",
      "[ True  True  True  True False False  True  True  True  True  True  True\n",
      " False  True  True False False  True  True  True False False  True  True\n",
      " False False False False] 0.08289739\n",
      "[False False  True False  True False  True False False  True False False\n",
      "  True  True  True  True False  True  True  True  True False False False\n",
      " False False False False] 0.07565392\n",
      "[ True  True  True False False  True  True  True False  True  True  True\n",
      "  True False  True False False  True  True False  True False  True False\n",
      "  True  True False  True] 0.07253521\n",
      "[False False  True  True  True False False False  True False  True False\n",
      "  True  True False False  True False  True False False  True  True False\n",
      " False False  True  True] 0.08028169\n",
      "[False  True False  True  True  True  True False False  True  True  True\n",
      " False False False  True False  True False False  True  True False  True\n",
      "  True False  True False] 0.08169014\n",
      "[ True False False  True  True  True  True False  True False  True  True\n",
      "  True False False False  True  True  True False False False False False\n",
      " False False False  True] 0.080181085\n",
      "[False  True False  True False False False False False  True  True  True\n",
      " False  True  True  True  True  True False  True False  True False False\n",
      " False  True  True False] 0.07424547\n",
      "[ True False False False False  True False  True False  True  True False\n",
      " False  True False False  True  True  True  True  True False False  True\n",
      " False False  True False] 0.069718316\n",
      "[False False False False False False  True  True False  True False False\n",
      " False False  True  True  True False False  True False False False  True\n",
      "  True  True False False] 0.069718316\n",
      "[False  True False  True  True  True False False  True False  True  True\n",
      " False False False False False  True False False False  True  True  True\n",
      "  True False  True  True] 0.07605634\n",
      "[ True  True False False  True False False  True  True  True  True False\n",
      " False False False False  True False  True False  True  True False False\n",
      " False  True  True False] 0.074245475\n",
      "[False  True False  True False False False  True False False False  True\n",
      " False False False False False False False False  True  True  True  True\n",
      "  True False False  True] 0.072434604\n",
      "[ True  True  True  True  True  True  True False  True  True False False\n",
      " False  True False  True  True False  True  True False False False  True\n",
      "  True False  True False] 0.08289739\n",
      "[False False  True  True  True False False False False  True  True  True\n",
      "  True  True False False  True False  True False False False  True False\n",
      " False  True  True False] 0.08249497\n",
      "[False False False False  True  True  True False  True  True  True False\n",
      "  True  True False  True False  True  True  True  True  True False False\n",
      "  True  True False  True] 0.07394366\n",
      "[ True False  True False False False False False  True False  True  True\n",
      " False  True False  True  True  True False  True  True  True  True  True\n",
      " False False  True False] 0.07887324\n",
      "[False False False False False  True  True False  True False False False\n",
      "  True False  True False False  True False False False  True  True  True\n",
      " False  True False False] 0.08008049\n",
      "[ True False  True  True  True  True False  True False False  True  True\n",
      " False False False  True False False  True False  True  True  True False\n",
      " False  True  True  True] 0.08239437\n",
      "[False  True  True False False False  True False  True  True False False\n",
      "  True  True  True  True False  True  True  True  True False False False\n",
      " False  True False False] 0.079879284\n",
      "[False  True False False  True  True False False  True  True  True  True\n",
      " False False False  True False False False False  True False  True False\n",
      "  True  True  True  True] 0.07082495\n",
      "[False  True False  True False  True False False  True False False False\n",
      "  True False  True False False  True False  True False False False  True\n",
      " False  True False  True] 0.075855136\n",
      "[False False  True False  True  True  True  True False  True False  True\n",
      "  True  True False False  True False False  True  True False False  True\n",
      " False  True False  True] 0.08289738\n",
      "[False False False False False  True False False  True  True  True False\n",
      "  True  True  True False  True False  True False  True False False False\n",
      "  True False False  True] 0.077565394\n",
      "[ True False  True  True  True False False  True False False False  True\n",
      "  True False  True  True False  True False  True False  True  True  True\n",
      "  True False  True  True] 0.080382295\n",
      "[False  True False  True False False  True  True  True  True  True False\n",
      "  True  True False False False  True False False False  True False  True\n",
      "  True  True False  True] 0.08249497\n",
      "[False  True False False False False False False  True  True  True False\n",
      " False False False False False False False  True  True  True  True  True\n",
      "  True False False False] 0.06991952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False False  True False False  True False False False  True\n",
      " False  True  True  True  True  True False False  True  True False  True\n",
      " False  True False  True] 0.080181085\n",
      "[False False False  True  True  True  True  True False False  True  True\n",
      "  True  True  True False False  True  True  True False False False  True\n",
      "  True  True False  True] 0.07595573\n",
      "[ True  True False False False False  True  True False False  True  True\n",
      " False  True False  True  True False False  True False False False False\n",
      "  True False False  True] 0.07273642\n",
      "[ True  True  True  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True False  True  True  True False False False\n",
      " False  True  True False] 0.08289739\n",
      "[ True  True  True False False  True  True False  True  True False False\n",
      "  True False  True False False False  True False False False  True False\n",
      " False  True  True  True] 0.07957747\n",
      "[False False  True False  True False False False  True False  True  True\n",
      "  True False False False  True  True False False  True False False  True\n",
      "  True False  True  True] 0.07414486\n",
      "[ True False False  True False  True False  True  True False False  True\n",
      "  True  True False  True False False  True  True  True False  True False\n",
      " False False  True False] 0.072434604\n",
      "[ True False False False False  True False False False  True False  True\n",
      " False  True  True  True  True  True False False False  True False  True\n",
      "  True False False False] 0.07253522\n",
      "[ True False False  True False False False  True False  True  True False\n",
      " False  True False False  True False False False  True  True  True False\n",
      "  True False  True  True] 0.07253522\n",
      "[False False  True  True False False False False False  True  True  True\n",
      " False  True  True  True  True  True False False False  True False  True\n",
      "  True  True False False] 0.080181085\n",
      "[False False  True False False False  True  True  True  True False False\n",
      " False False False  True False  True  True  True False  True  True False\n",
      "  True  True False False] 0.07987928\n",
      "[False  True  True  True  True  True  True False False  True False  True\n",
      "  True  True False  True  True False False  True  True  True  True False\n",
      "  True False False  True] 0.08269618\n",
      "[ True False False  True  True False  True False False  True False False\n",
      " False False False False  True False  True False  True False  True False\n",
      " False False False  True] 0.07977868\n",
      "[ True  True  True False False False  True False False False False  True\n",
      "  True  True  True  True  True False False False False False  True False\n",
      "  True  True  True  True] 0.07575453\n",
      "[False  True  True False  True False  True False  True False False False\n",
      " False  True False False False False False  True False  True False False\n",
      " False  True False  True] 0.08008049\n",
      "[ True False False False False  True False  True  True  True False  True\n",
      "  True  True False False False  True  True False  True False False False\n",
      " False False  True False] 0.07414488\n",
      "[False False  True  True False  True  True  True False  True False  True\n",
      " False False  True  True False  True  True  True False False  True False\n",
      " False False  True  True] 0.080382295\n",
      "[ True False  True False  True False  True False False  True False False\n",
      "  True False False False  True False False  True  True False  True  True\n",
      " False False False False] 0.0722334\n",
      "[False False False  True False  True  True False  True  True False False\n",
      "  True False False  True False  True False False  True  True False  True\n",
      " False  True False  True] 0.07997988\n",
      "[ True  True  True  True  True False  True False False  True  True  True\n",
      " False  True  True  True False False  True False  True  True False  True\n",
      "  True False  True  True] 0.08269618\n",
      "[ True False  True False  True  True  True False False  True  True False\n",
      "  True  True  True False  True  True  True  True  True  True  True False\n",
      " False  True  True  True] 0.0750503\n",
      "[False  True False  True  True False False False False  True  True False\n",
      " False  True  True False  True  True False False  True False False  True\n",
      " False  True  True  True] 0.07555332\n",
      "[False False False False False False  True False False  True  True False\n",
      " False  True  True False  True False  True False  True  True False  True\n",
      " False  True  True False] 0.07253521\n",
      "[ True False  True False  True  True  True False False False  True  True\n",
      " False False False  True False  True  True False  True  True False False\n",
      " False False  True False] 0.07595573\n",
      "[False False  True  True False False False False  True False False  True\n",
      " False  True False False  True False False False False  True False  True\n",
      "  True False  True False] 0.07786721\n",
      "[False False  True False  True  True False False False  True False False\n",
      "  True False  True False False False False  True  True  True False  True\n",
      "  True False False  True] 0.08008048\n",
      "[False  True  True False False  True  True False  True False False False\n",
      "  True  True  True False False  True  True  True  True  True False  True\n",
      "  True False False False] 0.07575453\n",
      "[ True False False  True False False  True False  True False  True False\n",
      " False  True False False False False  True False  True False False  True\n",
      "  True  True False False] 0.0806841\n",
      "[False  True False  True False  True False  True  True False False False\n",
      " False False False  True False False  True  True False False  True  True\n",
      "  True False  True False] 0.076559365\n",
      "[False False  True False  True  True False False False False False  True\n",
      " False  True  True False  True  True False  True False  True  True False\n",
      "  True False  True False] 0.075855136\n",
      "[ True  True False  True  True False  True  True False False  True  True\n",
      "  True False  True False False  True  True  True False  True  True False\n",
      " False False False  True] 0.07987928\n",
      "[False False False  True False False False False False False  True  True\n",
      " False False False  True False  True  True False  True False  True False\n",
      "  True  True False  True] 0.07253522\n",
      "[ True False False False  True False  True False  True  True False  True\n",
      "  True False False False False  True  True False False  True  True False\n",
      " False  True False  True] 0.08239437\n",
      "[ True False False  True False  True  True False False  True False  True\n",
      "  True  True False  True  True False False False False  True  True  True\n",
      "  True  True False False] 0.07987928\n",
      "[ True False  True False  True  True False False False  True False False\n",
      "  True False  True  True False False False  True False  True  True  True\n",
      " False False False  True] 0.07273642\n",
      "[False  True  True False False  True False  True  True False  True  True\n",
      " False False False False  True  True  True False  True  True False False\n",
      " False  True False  True] 0.072635815\n",
      "[ True False  True  True False  True False False  True False  True  True\n",
      "  True  True False  True False  True False False  True False  True False\n",
      " False False False False] 0.08249497\n",
      "[False False False False  True False  True  True False  True  True  True\n",
      "  True False  True False False False  True  True False  True False  True\n",
      "  True False  True  True] 0.07957747\n",
      "[False  True False  True  True False False False  True  True False False\n",
      "  True False  True False False False  True False False  True  True  True\n",
      " False  True False False] 0.07997988\n",
      "[ True  True False  True  True  True False False  True  True False False\n",
      " False False  True False False False  True  True  True  True  True  True\n",
      "  True  True  True False] 0.08199195\n",
      "[ True False  True  True False False False  True False False False  True\n",
      " False False False False  True False False  True False False  True  True\n",
      " False  True False  True] 0.07595573\n",
      "[ True  True False False  True False False  True  True  True  True False\n",
      " False False False False False  True  True False  True False  True False\n",
      " False False False False] 0.07555332\n",
      "[False False False  True  True False False False False False False False\n",
      " False  True False False  True False False False  True  True False False\n",
      " False  True False  True] 0.07575453\n",
      "[False  True  True  True False False  True False False  True False False\n",
      "  True  True  True False False False False  True False  True  True  True\n",
      " False  True  True False] 0.08028169\n",
      "[False  True False  True  True False False  True False  True  True  True\n",
      " False  True  True  True False  True False False  True False  True False\n",
      " False False  True  True] 0.08289739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True  True  True False  True  True False False False\n",
      "  True False False  True False  True False  True  True  True False False\n",
      " False  True  True False] 0.07997988\n",
      "[ True False  True  True  True  True  True  True False False  True  True\n",
      "  True  True  True False  True  True  True False  True False False  True\n",
      "  True False  True False] 0.08018109\n",
      "[False  True False  True  True False False False  True  True False False\n",
      "  True  True False False  True  True False False False False  True  True\n",
      "  True False  True False] 0.076861165\n",
      "[False False  True False  True  True False False False  True  True False\n",
      "  True  True False  True False False  True  True False False False  True\n",
      " False False  True  True] 0.0750503\n",
      "[ True  True  True  True  True  True False  True  True  True False  True\n",
      "  True  True False  True False  True  True  True False False False  True\n",
      "  True  True False  True] 0.082696185\n",
      "[False  True False  True  True  True False False  True False  True False\n",
      " False  True  True False  True  True False  True  True  True False  True\n",
      " False False False  True] 0.07816901\n",
      "[ True  True False  True False  True  True False  True False  True  True\n",
      " False  True  True  True False False  True False  True False False False\n",
      " False False  True False] 0.07535212\n",
      "[ True  True False False  True  True False False  True  True  True False\n",
      "  True False False False  True  True  True False False  True  True False\n",
      " False  True  True  True] 0.07273642\n",
      "[False False  True False False False False False False False False False\n",
      "  True False False  True False False False False  True  True  True  True\n",
      " False False  True False] 0.06991952\n",
      "[False False  True False  True  True  True False False  True  True  True\n",
      " False False  True False  True False  True  True  True  True  True  True\n",
      "  True  True  True  True] 0.08209255\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    mask = np.random.randint(2, size=(28), dtype='bool')\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # to_scale = scaler.fit_transform(df_item.iloc[:, 1:])[:, mask]\n",
    "    to_scale = df_item.iloc[:, 1:].values[:, mask]\n",
    "    \n",
    "    df_item_np = csr_matrix(to_scale)\n",
    "    item_sim = linear_kernel(df_item_np, dense_output=False)\n",
    "\n",
    "    model = LightFM(no_components=30, loss='warp', random_state=11)\n",
    "    model.fit(data_csr,\n",
    "              item_features=df_item_np,\n",
    "              epochs=20)\n",
    "\n",
    "    train_precision = precision_at_k(model, data_csr, item_features=df_item_np, k=20).mean()\n",
    "\n",
    "    print(mask, train_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:52:31.135633Z",
     "start_time": "2020-08-03T16:52:30.976898Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def sample_recommendation(model, data, user_ids, k=20):\n",
    "    n_users, n_items = data_csr.shape\n",
    "    items = np.arange(n_items)\n",
    "    answers = list()\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        scores = model.predict(user_id, items)\n",
    "        top_items = items[np.argsort(-scores)]\n",
    "        answers.append(top_items[:k])\n",
    "    return np.array(answers)\n",
    "\n",
    "pred = sample_recommendation(model, data, test.iloc[:, 0].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T06:44:00.824600Z",
     "start_time": "2020-08-04T06:44:00.819587Z"
    }
   },
   "outputs": [],
   "source": [
    "subm.iloc[:, 1:] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T06:44:01.855023Z",
     "start_time": "2020-08-04T06:44:01.839064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>76</td>\n",
       "      <td>66</td>\n",
       "      <td>200</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>22</td>\n",
       "      <td>65</td>\n",
       "      <td>232</td>\n",
       "      <td>405</td>\n",
       "      <td>402</td>\n",
       "      <td>229</td>\n",
       "      <td>240</td>\n",
       "      <td>239</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>216</td>\n",
       "      <td>311</td>\n",
       "      <td>276</td>\n",
       "      <td>402</td>\n",
       "      <td>399</td>\n",
       "      <td>232</td>\n",
       "      <td>391</td>\n",
       "      <td>274</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>413</td>\n",
       "      <td>390</td>\n",
       "      <td>230</td>\n",
       "      <td>168</td>\n",
       "      <td>405</td>\n",
       "      <td>411</td>\n",
       "      <td>239</td>\n",
       "      <td>432</td>\n",
       "      <td>388</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>216</td>\n",
       "      <td>232</td>\n",
       "      <td>413</td>\n",
       "      <td>230</td>\n",
       "      <td>276</td>\n",
       "      <td>352</td>\n",
       "      <td>408</td>\n",
       "      <td>311</td>\n",
       "      <td>239</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>173</td>\n",
       "      <td>240</td>\n",
       "      <td>399</td>\n",
       "      <td>274</td>\n",
       "      <td>411</td>\n",
       "      <td>272</td>\n",
       "      <td>374</td>\n",
       "      <td>156</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>286</td>\n",
       "      <td>173</td>\n",
       "      <td>216</td>\n",
       "      <td>178</td>\n",
       "      <td>262</td>\n",
       "      <td>413</td>\n",
       "      <td>274</td>\n",
       "      <td>168</td>\n",
       "      <td>311</td>\n",
       "      <td>296</td>\n",
       "      <td>...</td>\n",
       "      <td>230</td>\n",
       "      <td>276</td>\n",
       "      <td>352</td>\n",
       "      <td>408</td>\n",
       "      <td>391</td>\n",
       "      <td>440</td>\n",
       "      <td>73</td>\n",
       "      <td>184</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>216</td>\n",
       "      <td>262</td>\n",
       "      <td>413</td>\n",
       "      <td>168</td>\n",
       "      <td>311</td>\n",
       "      <td>173</td>\n",
       "      <td>276</td>\n",
       "      <td>274</td>\n",
       "      <td>230</td>\n",
       "      <td>...</td>\n",
       "      <td>296</td>\n",
       "      <td>408</td>\n",
       "      <td>214</td>\n",
       "      <td>352</td>\n",
       "      <td>229</td>\n",
       "      <td>440</td>\n",
       "      <td>302</td>\n",
       "      <td>396</td>\n",
       "      <td>382</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    0    1    2    3    4    5    6    7    8  ...   10   11   12  \\\n",
       "0      166   37   35   76   66  200   80   72    7   58  ...   60   22   65   \n",
       "1       26  216  311  276  402  399  232  391  274  173  ...  413  390  230   \n",
       "2       41  216  232  413  230  276  352  408  311  239  ...  168  173  240   \n",
       "3      286  173  216  178  262  413  274  168  311  296  ...  230  276  352   \n",
       "4      108  216  262  413  168  311  173  276  274  230  ...  296  408  214   \n",
       "\n",
       "    13   14   15   16   17   18   19  \n",
       "0  232  405  402  229  240  239  390  \n",
       "1  168  405  411  239  432  388  229  \n",
       "2  399  274  411  272  374  156  405  \n",
       "3  408  391  440   73  184   24   50  \n",
       "4  352  229  440  302  396  382  204  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T06:44:06.603442Z",
     "start_time": "2020-08-04T06:44:06.593445Z"
    }
   },
   "outputs": [],
   "source": [
    "subm.to_csv('input/subm002.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
